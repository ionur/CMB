{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20505,
     "status": "ok",
     "timestamp": 1647901070991,
     "user": {
      "displayName": "Ipek Ilayda Onur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12430611341563674312"
     },
     "user_tz": 240
    },
    "id": "4u5sNkej9C5H",
    "outputId": "e72fcb03-614a-444f-8fc2-404df2b4c604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Collecting import-ipynb\n",
      "  Downloading import-ipynb-0.1.3.tar.gz (4.0 kB)\n",
      "Building wheels for collected packages: import-ipynb\n",
      "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-py3-none-any.whl size=2975 sha256=7a1dd04fec2adad4d0744886cb8856cb9580d8a8b4093aae924360196449e0a2\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/5e/dc/79780689896a056199b0b9f24471e3ee184fbd816df355d5f0\n",
      "Successfully built import-ipynb\n",
      "Installing collected packages: import-ipynb\n",
      "Successfully installed import-ipynb-0.1.3\n",
      "/content/drive/My Drive/Colab Notebooks/10707\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from utils import get_grid, get_norm_layer, get_pad_layer\n",
    "\n",
    "sys.path.append('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = np.load('../Data/window_info.npz')\n",
    "window = torch.Tensor(window['taper']).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18969,
     "status": "ok",
     "timestamp": 1647901093957,
     "user": {
      "displayName": "Ipek Ilayda Onur",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12430611341563674312"
     },
     "user_tz": 240
    },
    "id": "SrqygLv_9GUk",
    "outputId": "92ae716f-6237-4f51-a9bc-0a130b6430ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        act = nn.ReLU(inplace=True)\n",
    "        input_ch = opt.input_ch\n",
    "        n_gf = opt.n_gf\n",
    "        norm = get_norm_layer(opt.norm_type)\n",
    "        output_ch = opt.output_ch\n",
    "        pad = get_pad_layer(opt.padding_type)\n",
    "\n",
    "        model = []\n",
    "        # model += [pad(3), nn.Conv2d(input_ch, n_gf, kernel_size=7, padding=0), norm(n_gf), act]\n",
    "        model += [nn.Conv2d(input_ch, n_gf, kernel_size=3, padding=1), norm(n_gf), act]\n",
    "\n",
    "\n",
    "        for _ in range(opt.n_downsample):\n",
    "            model += [nn.Conv2d(n_gf, 2 * n_gf, kernel_size=3, padding=1, stride=2), norm(2 * n_gf), act]\n",
    "            n_gf *= 2\n",
    "\n",
    "        for _ in range(opt.n_residual):\n",
    "            model += [ResidualBlock(n_gf, pad, norm, act)]\n",
    "\n",
    "        for _ in range(opt.n_downsample):\n",
    "            model += [nn.ConvTranspose2d(n_gf, n_gf//2, kernel_size=3, padding=1, stride=2, output_padding=1),\n",
    "                      norm(n_gf//2), act]\n",
    "            n_gf //= 2\n",
    "\n",
    "        # model += [pad(3), nn.Conv2d(n_gf, output_ch, kernel_size=7, padding=0)]\n",
    "        model += [nn.Conv2d(n_gf, output_ch, kernel_size=3, padding=1)]\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "        print(self)\n",
    "        print(\"the number of G parameters\", sum(p.numel() for p in self.parameters() if p.requires_grad))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x) * window\n",
    "        \n",
    "\n",
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(PatchDiscriminator, self).__init__()\n",
    "\n",
    "        act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        input_channel = opt.input_ch\n",
    "        n_df = opt.n_df\n",
    "        norm = nn.InstanceNorm2d\n",
    "\n",
    "        blocks = []\n",
    "        blocks += [[nn.Conv2d(input_channel, n_df, kernel_size=4, padding=1, stride=2), act]]\n",
    "        blocks += [[nn.Conv2d(n_df, 2 * n_df, kernel_size=4, padding=1, stride=2), norm(2 * n_df), act]]\n",
    "        blocks += [[nn.Conv2d(2 * n_df, 4 * n_df, kernel_size=4, padding=1, stride=2), norm(4 * n_df), act]]\n",
    "        blocks += [[nn.Conv2d(4 * n_df, 8 * n_df, kernel_size=4, padding=1, stride=1), norm(8 * n_df), act]]\n",
    "\n",
    "\n",
    "        blocks += [[nn.Conv2d(8 * n_df, 1, kernel_size=4, padding=1, stride=1)]]\n",
    "\n",
    "        self.n_blocks = len(blocks)\n",
    "        for i in range(self.n_blocks):\n",
    "            setattr(self, 'block_{}'.format(i), nn.Sequential(*blocks[i]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = [x]\n",
    "        for i in range(self.n_blocks):\n",
    "            block = getattr(self, 'block_{}'.format(i))\n",
    "            result.append(block(result[-1]))\n",
    "\n",
    "        return result[1:]  # except for the input\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        \n",
    "        for i in range(opt.n_D):\n",
    "            setattr(self, 'Scale_{}'.format(str(i)), PatchDiscriminator(opt))\n",
    "        self.n_D = 2\n",
    "\n",
    "        print(self)\n",
    "        print(\"the number of D parameters\", sum(p.numel() for p in self.parameters() if p.requires_grad))\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = []\n",
    "        for i in range(self.n_D):\n",
    "            result.append(getattr(self, 'Scale_{}'.format(i))(x))\n",
    "            if i != self.n_D - 1:\n",
    "                x = nn.AvgPool2d(kernel_size=3, padding=1, stride=2, count_include_pad=False)(x)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Loss(object):\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "        self.device = torch.device('cuda:0' if opt.gpu_ids != -1 else 'cpu:0')\n",
    "        self.dtype = torch.float16 if opt.data_type == 16 else torch.float32\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.FMcriterion = nn.L1Loss()\n",
    "        self.n_D = 2\n",
    "\n",
    "\n",
    "    def __call__(self, D, G, input, target):\n",
    "        loss_D = 0\n",
    "        loss_G = 0\n",
    "        loss_G_FM = 0\n",
    "\n",
    "        fake = G(input)\n",
    "\n",
    "        loss_L2 = self.criterion(fake, target)\n",
    "\n",
    "        # real_features = D(torch.cat((input, target), dim=1))\n",
    "        # fake_features = D(torch.cat((input, fake.detach()), dim=1))\n",
    "        real_features = D(target)\n",
    "        fake_features = D(fake.detach())\n",
    "\n",
    "        for i in range(self.n_D):\n",
    "            real_grid = get_grid(real_features[i][-1], is_real=True).to(self.device, self.dtype)\n",
    "            fake_grid = get_grid(fake_features[i][-1], is_real=False).to(self.device, self.dtype)\n",
    "            # it doesn't need to be fake_features\n",
    "\n",
    "            loss_D += (self.criterion(real_features[i][-1], real_grid) +\n",
    "                       self.criterion(fake_features[i][-1], fake_grid)) * 0.5\n",
    "\n",
    "        # fake_features = D(torch.cat((input, fake), dim=1))\n",
    "        fake_features = D(fake)\n",
    "\n",
    "        for i in range(self.n_D):\n",
    "            real_grid = get_grid(fake_features[i][-1], is_real=True).to(self.device, self.dtype)\n",
    "            loss_G += self.criterion(fake_features[i][-1], real_grid)\n",
    "            \n",
    "            for j in range(len(fake_features[0])):\n",
    "                loss_G_FM += self.FMcriterion(fake_features[i][j], real_features[i][j].detach())\n",
    "                \n",
    "            loss_G += loss_G_FM * (1.0 / self.opt.n_D) * self.opt.lambda_FM\n",
    "\n",
    "        return loss_D, loss_G, target, fake, loss_L2\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, n_channels, pad, norm, act):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        block = [pad(1), nn.Conv2d(n_channels, n_channels, kernel_size=3, padding=0, stride=1), norm(n_channels), act]\n",
    "        block += [pad(1), nn.Conv2d(n_channels, n_channels, kernel_size=3, padding=0, stride=1), norm(n_channels)]\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPg8g41zFZluX1TNL4WJQKD",
   "collapsed_sections": [],
   "name": "networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
