{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO5WZmL+XpK3wMEZq6qAke2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"wHLBoQc77vlk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647914337079,"user_tz":240,"elapsed":9648,"user":{"displayName":"Ipek Ilayda Onur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12430611341563674312"}},"outputId":"340b809d-5734-4909-90b7-574ec7fb022e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","import sys\n","import os\n","import torch\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/10707/')\n","!pip install import-ipynb\n","import import_ipynb\n"]},{"cell_type":"code","source":["notebooks = ['networks', 'utils','pipeline']\n","\n","for notebook in notebooks:\n","  source_path_file = '/content/drive/My Drive/Colab Notebooks/10707/{}.ipynb'.format(notebook)\n","  source_path_file = source_path_file.replace(' ', '\\\\ ')\n","  !cp $source_path_file '/content' # to copy the file from drive to colab\n","  !rsync -aP $source_path_file '/content/{}.ipynb'.format(notebook)\n","\n","\n","from networks import Discriminator, Generator, Loss\n","from pipeline import CustomDataset\n","from utils import Manager, update_lr, weights_init, calculate_2d_spectrum\n","import numpy as np\n","from tqdm import tqdm\n","import datetime\n","\n","torch.backends.cudnn.benchmark = True\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'"],"metadata":{"id":"q84RwD9570Mg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647914356571,"user_tz":240,"elapsed":19498,"user":{"displayName":"Ipek Ilayda Onur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12430611341563674312"}},"outputId":"665e24b9-1856-4b98-dcc7-a6d9fa998751"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: -c: line 0: syntax error near unexpected token `('\n","/bin/bash: -c: line 0: `rsync -aP $source_path_file '/content/{}.ipynb'.format(notebook)'\n","/bin/bash: -c: line 0: syntax error near unexpected token `('\n","/bin/bash: -c: line 0: `rsync -aP $source_path_file '/content/{}.ipynb'.format(notebook)'\n","/bin/bash: -c: line 0: syntax error near unexpected token `('\n","/bin/bash: -c: line 0: `rsync -aP $source_path_file '/content/{}.ipynb'.format(notebook)'\n","importing Jupyter notebook from networks.ipynb\n","Mounted at /content/drive\n","Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n","sending incremental file list\n","utils.ipynb\n","          6,961 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=0/1)\n","importing Jupyter notebook from utils.ipynb\n","Mounted at /content/drive\n","importing Jupyter notebook from pipeline.ipynb\n","Mounted at /content/drive\n","Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n"]}]},{"cell_type":"code","source":["class TrainCMB(object):\n","    def __init__(self, opts):\n","        opt, val_opt = opts[0], opts[1]\n","        self.device = torch.device('cuda:0' )\n","        # device = torch.device('cpu')\n","        self.dtype = torch.float16 if opt.data_type == 16 else torch.float32\n","\n","        train_dataset = CustomDataset(opt)\n","        val_dataset  = CustomDataset(val_opt)\n","\n","\n","        self.train_loader = DataLoader(dataset=train_dataset,\n","                                  batch_size=opt.batch_size,\n","                                  num_workers=opt.n_workers,\n","                                  shuffle=not opt.no_shuffle)\n","        \n","   \n","        self.val_loader = DataLoader(dataset=val_dataset,\n","                                batch_size=val_opt.batch_size,\n","                                num_workers=val_opt.n_workers,\n","                                shuffle=not val_opt.no_shuffle)     \n","\n","        self.G = Generator(opt).apply(weights_init).to(device=self.device, dtype=self.dtype)\n","        self.D = Discriminator(opt).apply(weights_init).to(device=self.device, dtype=self.dtype)\n","\n","        self.criterion = Loss(opt)\n","\n","        self.G_optim = torch.optim.Adam(self.G.parameters(), lr=opt.lr, betas=(opt.beta1, opt.beta2), eps=opt.eps)\n","        self.D_optim = torch.optim.Adam(self.D.parameters(), lr=opt.lr, betas=(opt.beta1, opt.beta2), eps=opt.eps)\n","\n","        self.val_loss = []\n","\n","\n","        #parameters for power spectrum loss\n","        ## variables to set up the size of the map\n","        self.num_pix = int(2**7)  # this is the number of pixels in a linear dimension\n","        self.pix_size  = 2.34375 # size of a pixel in arcminutes\n","        self.delta_ell = 50.\n","        self.ell_max = 3500.\n","\n","\n","\n","    def __call__(self, opt):\n","        if opt.latest and os.path.isfile(opt.model_dir + '/' + str(opt.latest) + '_dict.pt'):\n","            pt_file = torch.load(opt.model_dir + '/' + str(opt.latest) + '_dict.pt')\n","            init_epoch = pt_file['Epoch']\n","            print(\"Resume at epoch: \", init_epoch)\n","            self.G.load_state_dict(pt_file['G_state_dict'])\n","            self.D.load_state_dict(pt_file['D_state_dict'])\n","            self.G_optim.load_state_dict(pt_file['G_optim_state_dict'])\n","            self.D_optim.load_state_dict(pt_file['D_optim_state_dict'])\n","            current_step = init_epoch * len(self.data_loader)\n","\n","            for param_group in self.G_optim.param_groups:\n","                lr = param_group['lr']\n","        else:\n","            init_epoch = 1\n","            current_step = 0\n","\n","        manager = Manager(opt)\n","\n","        total_step = opt.n_epochs * len(self.train_loader)\n","        start_time = datetime.datetime.now()\n","\n","        init_lr = opt.lr\n","        lr = opt.lr\n","\n","        for epoch in range(init_epoch, opt.n_epochs + 1):\n","            for input, target, _, _ in tqdm(self.train_loader):\n","                self.G.train()\n","                \n","                current_step += 1\n","                input, target = input.to(device=self.device, dtype=self.dtype), target.to(self.device, dtype=self.dtype)\n","\n","                D_loss, G_loss, target_tensor, generated_tensor, L2_loss = self.criterion(self.D, self.G, input, target)\n","\n","                self.G_optim.zero_grad()\n","                G_loss.backward()\n","                self.G_optim.step()\n","\n","                self.D_optim.zero_grad()\n","                D_loss.backward()\n","                self.D_optim.step()\n","\n","                package = {   'Epoch': epoch,\n","                              'current_step': current_step,\n","                              'total_step': total_step,\n","                              'D_loss': D_loss.detach().item(),\n","                              'G_loss': G_loss.detach().item(),\n","                              'L2_loss': L2_loss.detach().item(),\n","                              'D_state_dict': self.D.state_dict(),\n","                              'G_state_dict': self.G.state_dict(),\n","                              'D_optim_state_dict': self.D_optim.state_dict(),\n","                              'G_optim_state_dict': self.G_optim.state_dict(),\n","                              'target_tensor': target_tensor,\n","                              'generated_tensor': generated_tensor.detach()}\n","\n","                manager(package)\n","                # if opt.val_during_train:\n","                if opt.val_during_train and (current_step % 28 == 0):\n","                    self.G.eval()\n","                    # test_image_dir = os.path.join(test_opt.image_dir, str(current_step))\n","                    # os.makedirs(test_image_dir, exist_ok=True)\n","                    # test_model_dir = test_opt.model_dir\n","                    for p in self.G.parameters():\n","                        p.requires_grad_(False)\n","\n","                    val_loss_ll = 0\n","                    val_loss_ps = 0\n","                    for input, target, _, name in tqdm(self.val_loader):\n","                        input, target = input.to(device=self.device, dtype=self.dtype), target.to(self.device, dtype=self.dtype)\n","                        fake = self.G(input)\n","                        ll = F.mse_loss(fake, target)\n","                        \n","                        ####only look at the first batch\n","                        if ll != 0:\n","                            val_loss_ll += ll.cpu().detach()\n","                            # ## make a power spectrum\n","                            #spectrum ground truth \n","                            ps_true = torch.tensor([ calculate_2d_spectrum(t.squeeze().cpu().detach(), t.squeeze().cpu().detach(),self.delta_ell,self.ell_max,self.pix_size,self.num_pix)[1] for t in target])\n","                            #spectrum generated \n","                            ps_fake = torch.tensor([ calculate_2d_spectrum(f.squeeze().cpu().detach(), f.squeeze().cpu().detach(),self.delta_ell,self.ell_max,self.pix_size,self.num_pix)[1] for f in fake])\n","\n","                            val_loss_ps += torch.tensor([ F.mse_loss(ps_true[i][1:], ps_fake[i][1:]) for i in range(len(ps_true))]).sum().detach()\n","\n","                            self.val_loss.append([val_loss_ll / len(input), val_loss_ps / len(input)])\n","                            break\n","                        # UpIB = opt.saturation_upper_limit_target\n","                        # LoIB = opt.saturation_lower_limit_target\n","                            \n","                        # np_fake = fake.cpu().numpy().squeeze() \n","                        # np_real = target.cpu().numpy().squeeze() \n","                            \n","                        # manager.save_image(np_fake, path=os.path.join(test_image_dir, 'Check_{:d}_'.format(current_step)+ name[0] + '_fake.png'))\n","                        # manager.save_image(np_real, path=os.path.join(test_image_dir, 'Check_{:d}_'.format(current_step)+ name[0] + '_real.png'))\n","\n","                    for p in self.G.parameters():\n","                        p.requires_grad_(True)\n","\n","            if epoch > opt.epoch_decay :\n","                lr = update_lr(lr, init_lr, opt.n_epochs - opt.epoch_decay, self.D_optim, self.G_optim)\n","\n","        print(\"Total time taken: \", datetime.datetime.now() - start_time)"],"metadata":{"id":"WGsKBXLA70oF","executionInfo":{"status":"ok","timestamp":1647915123384,"user_tz":240,"elapsed":356,"user":{"displayName":"Ipek Ilayda Onur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12430611341563674312"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"t2Ktmk3csg8H","executionInfo":{"status":"ok","timestamp":1647915300457,"user_tz":240,"elapsed":122,"user":{"displayName":"Ipek Ilayda Onur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12430611341563674312"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"q8amNXvkseg5","executionInfo":{"status":"ok","timestamp":1647915311130,"user_tz":240,"elapsed":126,"user":{"displayName":"Ipek Ilayda Onur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12430611341563674312"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wnBrASEeSncR","executionInfo":{"status":"ok","timestamp":1647915132037,"user_tz":240,"elapsed":127,"user":{"displayName":"Ipek Ilayda Onur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12430611341563674312"}},"outputId":"16b5aedb-92ea-43f8-87d6-dad7de71729a"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[tensor(1.0615), tensor(1.5887e-09, dtype=torch.float64)]]"]},"metadata":{},"execution_count":23}]}]}