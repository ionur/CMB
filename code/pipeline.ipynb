{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pipeline.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1qaRPsJCbtO","executionInfo":{"status":"ok","timestamp":1647825394371,"user_tz":240,"elapsed":31073,"user":{"displayName":"Ipek Ilayda Onur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12430611341563674312"}},"outputId":"efd38eaa-dba1-46f0-c422-035f2a0683a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Collecting import-ipynb\n","  Downloading import-ipynb-0.1.3.tar.gz (4.0 kB)\n","Building wheels for collected packages: import-ipynb\n","  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-py3-none-any.whl size=2975 sha256=ed0152aca798499b86a74c08270cad3c9fc860af8c0f84317b57440bf65f6ac7\n","  Stored in directory: /root/.cache/pip/wheels/b1/5e/dc/79780689896a056199b0b9f24471e3ee184fbd816df355d5f0\n","Successfully built import-ipynb\n","Installing collected packages: import-ipynb\n","Successfully installed import-ipynb-0.1.3\n","/content/drive/My Drive/Colab Notebooks/10707\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/10707/')\n","!pip install import-ipynb\n","import import_ipynb\n"]},{"cell_type":"code","source":["import os\n","from astropy.io import fits\n","from os.path import split, splitext\n","from glob import glob\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","from scipy.ndimage import rotate\n","from random import randint\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, opt):\n","        super(CustomDataset, self).__init__()\n","        self.opt = opt\n","        dataset_dir = opt.dataset_dir\n","        self.input_format = opt.data_format_input\n","        self.target_format = opt.data_format_target\n","\n","        if opt.is_train:\n","            self.label_path_list = sorted(glob(os.path.join(dataset_dir, 'Train', 'Input', '*.' + self.input_format)))\n","            self.target_path_list = sorted(glob(os.path.join(dataset_dir, 'Train', 'Target', '*.' + self.target_format)))\n","        elif opt.is_val:\n","            self.label_path_list = sorted(glob(os.path.join(dataset_dir, 'Val', 'Input', '*.' + self.input_format)))\n","            self.target_path_list = sorted(glob(os.path.join(dataset_dir, 'Val', 'Target', '*.' + self.target_format)))\n","        else:\n","            self.label_path_list = sorted(glob(os.path.join(dataset_dir, 'Test', 'Input', '*.' + self.input_format)))\n","            self.target_path_list = sorted(glob(os.path.join(dataset_dir, 'Test', 'Target', '*.' + self.target_format)))\n","    def __getitem__(self, index):\n","        list_transforms = []\n","        list_transforms += []\n","\n","        # [ Training data ] ==============================================================================================\n","        if self.opt.is_train:\n","            self.angle = randint(-self.opt.max_rotation_angle, self.opt.max_rotation_angle)\n","\n","            self.offset_x = randint(0, 2 * self.opt.padding_size - 1) if self.opt.padding_size > 0 else 0\n","            self.offset_y = randint(0, 2 * self.opt.padding_size - 1) if self.opt.padding_size > 0 else 0\n","            \n","            # [ Input ] ==================================================================================================\n","            if self.input_format in [\"fits\", \"fts\"]:\n","                IMG_A0 = np.array(fits.open(self.label_path_list[index])[0].data)\n","            elif self.input_format in [\"npy\"]:\n","\n","                IMG_A0 = np.load(self.label_path_list[index], allow_pickle=True)\n","            else:\n","                NotImplementedError(\"Please check data_format_input option. It has to be fits or npy.\")\n","\n","            #--------------------------------------\n","            if len(IMG_A0.shape) == 3:\n","                IMG_A0 = IMG_A0.transpose(2, 0 ,1)\n","            # --------------------------------------\n","\n","            IMG_A0[np.isnan(IMG_A0)] = 1\n","            # UpIA = np.float(self.opt.saturation_upper_limit_input)\n","            # LoIA = np.float(self.opt.saturation_lower_limit_input)\n","            label_array = IMG_A0\n","            # label_array = np.log10(np.clip(IMG_A0, LoIA, UpIA))/(np.log10(UpIA) - np.log10(LoIA)) *2 - 1\n","            \n","            # label_array = self.__rotate(label_array)\n","            # label_array = self.__pad(label_array, self.opt.padding_size)\n","            # label_array = self.__random_crop(label_array)\n","            \n","            label_tensor = torch.tensor(label_array)\n","\n","            if len(label_tensor.shape) == 2:\n","                label_tensor = label_tensor.unsqueeze(dim=0)\n","            \n","                \n","            # [ Target ] ==================================================================================================\n","            \n","            if self.target_format in [\"fits\", \"fts\"]:\n","                IMG_B0 = np.array(fits.open(self.target_path_list[index])[0].data)\n","            elif self.target_format in [\"npy\"]:\n","                IMG_B0 = np.load(self.target_path_list[index], allow_pickle=True)\n","            else:\n","                NotImplementedError(\"Please check data_format_target option. It has to be fits or npy.\")\n","                \n","            IMG_B0[np.isnan(IMG_B0)] = 0\n","            # UpIB = np.float(self.opt.saturation_upper_limit_target)\n","            # LoIB = np.float(self.opt.saturation_lower_limit_target)\n","            target_array = IMG_B0\n","            # target_array = (np.clip(IMG_B0, LoIB, UpIB)-(UpIB+ LoIB))/((UpIB - LoIB)/2)\n","            \n","            # target_array = self.__rotate(target_array)\n","            # target_array = self.__pad(target_array, self.opt.padding_size)\n","            # target_array = self.__random_crop(target_array)\n","            \n","            target_tensor = torch.tensor(target_array, dtype=torch.float32)\n","\n","            if len(target_tensor.shape) == 2:\n","                target_tensor = target_tensor.unsqueeze(dim=0)  # Add channel dimension.\n","\n","        # [ Test data ] ===================================================================================================\n","        else:\n","            # [ Input ] ==================================================================================================\n","            if self.input_format in [\"fits\", \"fts\"]:                    \n","                IMG_A0 = np.array(fits.open(self.label_path_list[index])[0].data)\n","            elif self.input_format in [\"npy\"]:\n","                IMG_A0 = np.load(self.label_path_list[index], allow_pickle=True)\n","            else:\n","                NotImplementedError(\"Please check data_format_input option. It has to be fits or npy.\")\n","                \n","            IMG_A0[np.isnan(IMG_A0)] = 1\n","            # UpIA = np.float(self.opt.saturation_upper_limit_input)\n","            # LoIA = np.float(self.opt.saturation_lower_limit_input)\n","            label_array = IMG_A0\n","            # label_array = np.log10(np.clip(IMG_A0, LoIA, UpIA))/(np.log10(UpIA) - np.log10(LoIA)) *2 - 1\n","            label_tensor = torch.tensor(label_array, dtype=torch.float32)\n","            \n","            if len(label_tensor.shape) == 2:\n","                label_tensor = label_tensor.unsqueeze(dim=0)\n","\n","            # [ Target ] ==================================================================================================\n","            \n","            if self.target_format in [\"fits\", \"fts\"]:\n","                IMG_B0 = np.array(fits.open(self.target_path_list[index])[0].data)\n","            elif self.target_format in [\"npy\"]:\n","                IMG_B0 = np.load(self.target_path_list[index], allow_pickle=True)\n","            else:\n","                NotImplementedError(\"Please check data_format_target option. It has to be fits or npy.\")\n","                \n","            IMG_B0[np.isnan(IMG_B0)] = 0\n","            # UpIB = np.float(self.opt.saturation_upper_limit_target)\n","            # LoIB = np.float(self.opt.saturation_lower_limit_target)\n","            target_array = IMG_B0\n","            # target_array = (np.clip(IMG_B0, LoIB, UpIB)-(UpIB+ LoIB))/((UpIB - LoIB)/2)\n","            \n","            # target_array = self.__rotate(target_array)\n","            # target_array = self.__pad(target_array, self.opt.padding_size)\n","            # target_array = self.__random_crop(target_array)\n","            \n","            target_tensor = torch.tensor(target_array, dtype=torch.float32)\n","\n","            if len(target_tensor.shape) == 2:\n","                target_tensor = target_tensor.unsqueeze(dim=0)  # Add channel dimension.\n","                \n","            \n","            return label_tensor, target_tensor, splitext(split(self.label_path_list[index])[-1])[0], \\\n","                        splitext(split(self.target_path_list[index])[-1])[0]\n","        \n","        return label_tensor, target_tensor, splitext(split(self.label_path_list[index])[-1])[0], \\\n","                   splitext(split(self.target_path_list[index])[-1])[0]\n","                   \n","    def __random_crop(self, x):\n","        x = np.array(x)\n","        x = x[self.offset_x: self.offset_x + 1024, self.offset_y: self.offset_y + 1024]\n","        return x\n","        # return Image.fromarray(x)\n","\n","    @staticmethod\n","    def __pad(x, padding_size):\n","        if type(padding_size) == int:\n","            if len(x.shape) == 3:\n","                padding_size= ((0, 0), (padding_size, padding_size), (padding_size, padding_size))\n","            else:\n","                padding_size = ((padding_size, padding_size), (padding_size, padding_size))\n","        return np.pad(x, pad_width=padding_size, mode=\"constant\", constant_values=0)\n","\n","    def __rotate(self, x):\n","        return rotate(x, self.angle, reshape=False)\n","\n","    @staticmethod\n","    def __to_numpy(x):\n","        return np.array(x, dtype=np.float32)\n","\n","    def __len__(self):\n","        return len(self.label_path_list)"],"metadata":{"id":"P5PsDQs0CgFD"},"execution_count":null,"outputs":[]}]}